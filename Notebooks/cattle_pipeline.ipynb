{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOb+xDM3VUWvV/E9fE6G5UI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahbhavya7/cattle_model/blob/main/Notebooks/cattle_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "acMDpNdJMnWa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats.mstats import winsorize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=pd.read_excel('cattle_analysis.xlsx')"
      ],
      "metadata": {
        "id": "YhSbgUlMM7NC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info()"
      ],
      "metadata": {
        "id": "o8QoOsMRNFjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix=ds.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0f4_MGJsrEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.columns"
      ],
      "metadata": {
        "id": "EDe2YOeOx43E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isnull().sum()"
      ],
      "metadata": {
        "id": "XAVuIEEHNLRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.duplicated().sum()"
      ],
      "metadata": {
        "id": "55uBIcBwNxfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=ds.drop(columns=['AnimalNo'])"
      ],
      "metadata": {
        "id": "XWWcvZKAZZ8L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=ds.iloc[:,:-1]\n",
        "y=ds.iloc[:,-1]"
      ],
      "metadata": {
        "id": "ccNcGhKYN20G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "n8_1Rgx17Ms6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X_train.columns:\n",
        "  sns.boxplot(data=X_train,x=col)\n",
        "  plt.show()\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "kCZiDBc7ZtYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_limits(X,lower=0.02,upper=0.98):\n",
        "  limits={col:(np.quantile(X[col],lower),(np.quantile(X[col],upper))) for col in X.columns}\n",
        "  return limits"
      ],
      "metadata": {
        "id": "r7XTeBcs8qZA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_limits(X,limits):\n",
        "  X_win=X.copy()\n",
        "  for col in X.columns:\n",
        "    lower,upper=limits[col]\n",
        "    X_win[col]=np.clip(X[col],lower,upper)\n",
        "  return X_win"
      ],
      "metadata": {
        "id": "hSxrelqN--Qd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_manual_cap_limits(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_limit = Q1 - 1.5 * IQR\n",
        "    upper_limit = Q3 + 1.5 * IQR\n",
        "    return lower_limit, upper_limit"
      ],
      "metadata": {
        "id": "PlhDYEl4cw2k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Winsorizer(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,lower=0.02,upper=0.98):\n",
        "    self.lower=lower\n",
        "    self.upper=upper\n",
        "    self.limits={}\n",
        "\n",
        "  def fit(self,X,y=None):\n",
        "    self.limits=get_limits(X,self.lower,self.upper)\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "    return apply_limits(X,self.limits)"
      ],
      "metadata": {
        "id": "W_ZrNSoU_svi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Manual_capper(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,column):\n",
        "    self.column=column\n",
        "    self.limits=(None,None)\n",
        "\n",
        "  def fit(self,X,y=None):\n",
        "    self.limits=get_manual_cap_limits(X,self.column)\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "    X_new=X.copy()\n",
        "    lower,upper=self.limits\n",
        "    X_new[self.column]=np.clip(X_new[self.column],lower,upper)\n",
        "    return X_new"
      ],
      "metadata": {
        "id": "gcLrCZTOBPto"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_new = X.copy()\n",
        "        X_new['Rump_Wither_Ratio'] = X_new['Rumpheight'] / X_new['WHHeightAtWither']\n",
        "        X_new['Length_Wither_Ratio'] = X_new['BLBodylengthcm'] / X_new['WHHeightAtWither']\n",
        "        X_new = X_new.drop(columns=['Rumpheight','WHHeightAtWither','BLBodylengthcm'])\n",
        "        return X_new"
      ],
      "metadata": {
        "id": "Ca53Pf7qDCQp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_regression(y_test, y_pred):\n",
        "    # Calculate errors\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mean_y = np.mean(y_test)\n",
        "\n",
        "    # Percentages\n",
        "    rmse_percent = (rmse / mean_y) * 100\n",
        "    mae_percent = (mae / mean_y) * 100\n",
        "\n",
        "    # Quality assessment (combined RMSE% and R²)\n",
        "    if rmse_percent < 5 and r2 > 0.85:\n",
        "        quality = \"Excellent\"\n",
        "    elif rmse_percent < 10 and r2 > 0.75:\n",
        "        quality = \"Good\"\n",
        "    elif rmse_percent < 15 and r2 > 0.6:\n",
        "        quality = \"Acceptable\"\n",
        "    else:\n",
        "        quality = \"Poor\"\n",
        "\n",
        "    # Print results\n",
        "    print(f\"RMSE: {rmse:.2f} kg ({rmse_percent:.1f}% of mean weight)\")\n",
        "    print(f\"MAE: {mae:.2f} kg ({mae_percent:.1f}% of mean weight)\")\n",
        "    print(f\"R²: {r2:.3f}\")\n",
        "    print(f\"Model Quality: {quality}\")\n",
        "\n",
        "    return rmse, mae, r2, quality\n"
      ],
      "metadata": {
        "id": "2ZJIpMtF9JFb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge,Lasso ,LinearRegression,ElasticNet\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "base_pipeline = Pipeline([\n",
        "    ('features',FeatureEngineer()),\n",
        "    ('winsor', Winsorizer()),\n",
        "    ('capper', Manual_capper('CannonBoneDiameter')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model',ElasticNet())\n",
        "])\n",
        "\n",
        "base_pipeline.fit(X_train, y_train)\n",
        "y_pred = base_pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "W3RUUWYOBCNu"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_regression(y_test, y_pred)"
      ],
      "metadata": {
        "id": "8qlFV1ek-JmW",
        "outputId": "0bceac49-d08f-4701-fa87-72b167401eae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 37.29 kg (6.2% of mean weight)\n",
            "MAE: 28.25 kg (4.7% of mean weight)\n",
            "R²: 0.811\n",
            "Model Quality: Good\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(37.291349736953144), 28.2502631348255, 0.8114077259562648, 'Good')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet(),\n",
        "    'RandomForest': RandomForestRegressor(),\n",
        "    'XGBoost': XGBRegressor()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    pipeline = Pipeline([\n",
        "        ('features',FeatureEngineer()),\n",
        "        ('winsor', Winsorizer()),\n",
        "        ('capper', Manual_capper('CannonBoneDiameter')),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model',model)\n",
        "    ])\n",
        "    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
        "    rmse = -np.mean(scores)\n",
        "    rmse_percent = (rmse / y_train.mean()) * 100\n",
        "    print(f\"{name}: CV RMSE = {rmse:.2f} kg ({rmse_percent:.1f}% of mean weight)\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zN0WdNpfht3C",
        "outputId": "c431caed-7433-456b-ed21-2433c00528f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression: CV RMSE = 30.10 kg (5.0% of mean weight)\n",
            "Ridge: CV RMSE = 30.09 kg (5.0% of mean weight)\n",
            "Lasso: CV RMSE = 30.16 kg (5.0% of mean weight)\n",
            "ElasticNet: CV RMSE = 32.83 kg (5.4% of mean weight)\n",
            "RandomForest: CV RMSE = 32.33 kg (5.4% of mean weight)\n",
            "XGBoost: CV RMSE = 35.15 kg (5.8% of mean weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Define your preprocessing pipeline template\n",
        "def create_pipeline(model, scale=True):\n",
        "    steps = [\n",
        "        ('features', FeatureEngineer()),\n",
        "        ('winsor', Winsorizer()),\n",
        "        ('capper', Manual_capper('CannonBoneDiameter'))\n",
        "    ]\n",
        "    if scale:\n",
        "        steps.append(('scaler', StandardScaler()))\n",
        "    steps.append(('model', model))\n",
        "    return Pipeline(steps)\n",
        "\n",
        "# Linear models\n",
        "linear_models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet()\n",
        "}\n",
        "\n",
        "param_grids_linear = {\n",
        "    'LinearRegression': {},  # no hyperparameters\n",
        "    'Ridge': {'model__alpha': [0.01, 0.1, 1.0, 10.0]},\n",
        "    'Lasso': {'model__alpha': [0.01, 0.1, 1.0, 10.0]},\n",
        "    'ElasticNet': {'model__alpha': [0.01,0.1,1.0], 'model__l1_ratio':[0.2,0.5,0.8]}\n",
        "}\n",
        "\n",
        "print(\"=== Linear Models (GridSearchCV) ===\")\n",
        "for name, model in linear_models.items():\n",
        "    pipeline = create_pipeline(model, scale=True)\n",
        "    grid = GridSearchCV(pipeline, param_grid=param_grids_linear[name],\n",
        "                        cv=5, scoring='neg_root_mean_squared_error')\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    best_rmse = -grid.best_score_\n",
        "    best_rmse_percent = (best_rmse / y_train.mean()) * 100\n",
        "    print(f\"{name}: Best CV RMSE = {best_rmse:.2f} kg ({best_rmse_percent:.1f}% of mean weight), Best params: {grid.best_params_}\")\n",
        "\n",
        "# Tree/boosting models\n",
        "tree_models = {\n",
        "    'RandomForest': RandomForestRegressor(random_state=42),\n",
        "    'XGBoost': XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "param_dists_tree = {\n",
        "    'RandomForest': {\n",
        "        'model__n_estimators': [100, 200, 500],\n",
        "        'model__max_depth': [None, 5, 10, 20],\n",
        "        'model__min_samples_split': [2, 5, 10],\n",
        "        'model__min_samples_leaf': [1, 2, 4]\n",
        "    },\n",
        "    'XGBoost': {\n",
        "        'model__n_estimators': [100, 200, 500],\n",
        "        'model__learning_rate': [0.01, 0.05, 0.1],\n",
        "        'model__max_depth': [3, 5, 7, 10],\n",
        "        'model__colsample_bytree': [0.6, 0.8, 1.0]\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"\\n=== Tree/Boosting Models (RandomizedSearchCV) ===\")\n",
        "for name, model in tree_models.items():\n",
        "    pipeline = create_pipeline(model, scale=False)  # trees don't need scaling\n",
        "    random_search = RandomizedSearchCV(\n",
        "        pipeline, param_distributions=param_dists_tree[name],\n",
        "        n_iter=20, cv=5, scoring='neg_root_mean_squared_error', random_state=42\n",
        "    )\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    best_rmse = -random_search.best_score_\n",
        "    best_rmse_percent = (best_rmse / y_train.mean()) * 100\n",
        "    print(f\"{name}: Best CV RMSE = {best_rmse:.2f} kg ({best_rmse_percent:.1f}% of mean weight), Best params: {random_search.best_params_}\")\n"
      ],
      "metadata": {
        "id": "ZDMobsmpkGFl",
        "outputId": "5358b5b3-105f-427c-9abd-cb0f18a72705",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Linear Models (GridSearchCV) ===\n",
            "LinearRegression: Best CV RMSE = 30.10 kg (5.0% of mean weight), Best params: {}\n",
            "Ridge: Best CV RMSE = 30.09 kg (5.0% of mean weight), Best params: {'model__alpha': 1.0}\n",
            "Lasso: Best CV RMSE = 30.09 kg (5.0% of mean weight), Best params: {'model__alpha': 0.1}\n",
            "ElasticNet: Best CV RMSE = 30.09 kg (5.0% of mean weight), Best params: {'model__alpha': 0.01, 'model__l1_ratio': 0.2}\n",
            "\n",
            "=== Tree/Boosting Models (RandomizedSearchCV) ===\n",
            "RandomForest: Best CV RMSE = 32.04 kg (5.3% of mean weight), Best params: {'model__n_estimators': 200, 'model__min_samples_split': 5, 'model__min_samples_leaf': 2, 'model__max_depth': 10}\n",
            "XGBoost: Best CV RMSE = 32.25 kg (5.3% of mean weight), Best params: {'model__n_estimators': 500, 'model__max_depth': 3, 'model__learning_rate': 0.1, 'model__colsample_bytree': 0.8}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Fit pipelines once\n",
        "pipeline_ridge = create_pipeline(Ridge(alpha=1.0), scale=True).fit(X_train, y_train)\n",
        "pipeline_lasso = create_pipeline(Lasso(alpha=0.1), scale=True).fit(X_train, y_train)\n",
        "pipeline_en = create_pipeline(ElasticNet(alpha=0.01, l1_ratio=0.2), scale=True).fit(X_train, y_train)\n",
        "\n",
        "# Precompute out-of-fold predictions for weight optimization\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds = []\n",
        "\n",
        "for pipeline in [pipeline_ridge, pipeline_lasso, pipeline_en]:\n",
        "    preds = np.zeros(len(X_train))\n",
        "    for train_idx, val_idx in kf.split(X_train):\n",
        "        pipeline.fit(X_train.iloc[train_idx], y_train.iloc[train_idx])\n",
        "        preds[val_idx] = pipeline.predict(X_train.iloc[val_idx])\n",
        "    oof_preds.append(preds)\n",
        "\n",
        "oof_preds = np.array(oof_preds)  # shape: (3 models, n_samples)\n",
        "\n",
        "# Fast weight search using coarse grid\n",
        "weight_options = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
        "best_rmse = np.inf\n",
        "best_weights = None\n",
        "\n",
        "for w_ridge in weight_options:\n",
        "    for w_lasso in weight_options:\n",
        "        for w_en in weight_options:\n",
        "            if w_ridge + w_lasso + w_en == 0:\n",
        "                continue\n",
        "            weights = np.array([w_ridge, w_lasso, w_en])\n",
        "            weights = weights / weights.sum()\n",
        "            ensemble_pred = np.dot(weights, oof_preds)\n",
        "            rmse = np.sqrt(mean_squared_error(y_train, ensemble_pred))\n",
        "            if rmse < best_rmse:\n",
        "                best_rmse = rmse\n",
        "                best_weights = weights\n",
        "\n",
        "# Make final weighted predictions on test set\n",
        "preds_test = (\n",
        "    best_weights[0] * pipeline_ridge.predict(X_test) +\n",
        "    best_weights[1] * pipeline_lasso.predict(X_test) +\n",
        "    best_weights[2] * pipeline_en.predict(X_test)\n",
        ")\n",
        "\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, preds_test))\n",
        "rmse_percent = (rmse_test / y_test.mean()) * 100\n",
        "\n",
        "print(f\"Best weights: Ridge={best_weights[0]:.2f}, Lasso={best_weights[1]:.2f}, ElasticNet={best_weights[2]:.2f}\")\n",
        "print(f\"Weighted Ensemble RMSE: {rmse_test:.2f} kg ({rmse_percent:.1f}% of mean weight)\")\n"
      ],
      "metadata": {
        "id": "_E5UTNRGlFOL",
        "outputId": "93783e1d-77b0-4948-afe9-c62ea70d7884",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best weights: Ridge=0.00, Lasso=0.20, ElasticNet=0.80\n",
            "Weighted Ensemble RMSE: 33.09 kg (5.5% of mean weight)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for col in X_train_win.columns:\n",
        "#   sns.boxplot(data=X_train_win,x=col)\n",
        "#   plt.show()\n",
        "#   print('\\n')"
      ],
      "metadata": {
        "id": "V2zJyIkwcKCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew_result = X_win.skew(numeric_only=True).to_dict()\n",
        "# print(skew_result)"
      ],
      "metadata": {
        "id": "d9Vc004VdPgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew_result = y_win.skew(numeric_only=True)\n",
        "# print(skew_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q6j9Dv_dnXR",
        "outputId": "aa63fdc8-e7b4-499b-9045-e7b5acb8a660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12408513676691647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE: 30.04 kg (5.0% of mean weight)\n",
        "MAE: 22.97 kg (3.8% of mean weight)\n",
        "R²: 0.866\n",
        "Model Quality: Good\n",
        "(np.float64(30.039672370500533), 22.9675643106626, 0.866380202946881, 'Good')"
      ],
      "metadata": {
        "id": "Mzrqg-N5NYmR"
      }
    }
  ]
}