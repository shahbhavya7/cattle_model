{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a33212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2a6f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Processed/cattle_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ce40e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartGirth</th>\n",
       "      <th>AbdGirth</th>\n",
       "      <th>ChestDepth</th>\n",
       "      <th>ActualBodyWeight</th>\n",
       "      <th>HG_to_AG</th>\n",
       "      <th>HG_to_CD</th>\n",
       "      <th>AG_to_CD</th>\n",
       "      <th>HG_minus_AG</th>\n",
       "      <th>HG_minus_CD</th>\n",
       "      <th>AG_minus_CD</th>\n",
       "      <th>HGxAG</th>\n",
       "      <th>HGxCD</th>\n",
       "      <th>AGxCD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172</td>\n",
       "      <td>217</td>\n",
       "      <td>83</td>\n",
       "      <td>379</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>2.072289</td>\n",
       "      <td>2.614458</td>\n",
       "      <td>-45</td>\n",
       "      <td>89</td>\n",
       "      <td>134</td>\n",
       "      <td>37324</td>\n",
       "      <td>14276</td>\n",
       "      <td>18011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>215</td>\n",
       "      <td>85</td>\n",
       "      <td>398</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>2.023529</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>-43</td>\n",
       "      <td>87</td>\n",
       "      <td>130</td>\n",
       "      <td>36980</td>\n",
       "      <td>14620</td>\n",
       "      <td>18275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>188</td>\n",
       "      <td>217</td>\n",
       "      <td>95</td>\n",
       "      <td>407</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>1.978947</td>\n",
       "      <td>2.284211</td>\n",
       "      <td>-29</td>\n",
       "      <td>93</td>\n",
       "      <td>122</td>\n",
       "      <td>40796</td>\n",
       "      <td>17860</td>\n",
       "      <td>20615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>185</td>\n",
       "      <td>203</td>\n",
       "      <td>82</td>\n",
       "      <td>412</td>\n",
       "      <td>0.911330</td>\n",
       "      <td>2.256098</td>\n",
       "      <td>2.475610</td>\n",
       "      <td>-18</td>\n",
       "      <td>103</td>\n",
       "      <td>121</td>\n",
       "      <td>37555</td>\n",
       "      <td>15170</td>\n",
       "      <td>16646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>179</td>\n",
       "      <td>216</td>\n",
       "      <td>84</td>\n",
       "      <td>413</td>\n",
       "      <td>0.828704</td>\n",
       "      <td>2.130952</td>\n",
       "      <td>2.571429</td>\n",
       "      <td>-37</td>\n",
       "      <td>95</td>\n",
       "      <td>132</td>\n",
       "      <td>38664</td>\n",
       "      <td>15036</td>\n",
       "      <td>18144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HeartGirth  AbdGirth  ChestDepth  ActualBodyWeight  HG_to_AG  HG_to_CD  \\\n",
       "0         172       217          83               379  0.792627  2.072289   \n",
       "1         172       215          85               398  0.800000  2.023529   \n",
       "2         188       217          95               407  0.866359  1.978947   \n",
       "3         185       203          82               412  0.911330  2.256098   \n",
       "4         179       216          84               413  0.828704  2.130952   \n",
       "\n",
       "   AG_to_CD  HG_minus_AG  HG_minus_CD  AG_minus_CD  HGxAG  HGxCD  AGxCD  \n",
       "0  2.614458          -45           89          134  37324  14276  18011  \n",
       "1  2.529412          -43           87          130  36980  14620  18275  \n",
       "2  2.284211          -29           93          122  40796  17860  20615  \n",
       "3  2.475610          -18          103          121  37555  15170  16646  \n",
       "4  2.571429          -37           95          132  38664  15036  18144  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47b3c79f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(517, 13)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "881ab640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('ActualBodyWeight', axis=1)\n",
    "y = df['ActualBodyWeight']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4b59a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0182cb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scaling the data using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4adb605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import  Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcc6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge:\n",
      "RMSE: 34.26 kg (5.7% of mean weight)\n",
      "MAE: 26.01 kg\n",
      "R²: 0.841\n",
      "Model Quality: Good\n",
      "\n",
      "Lasso:\n",
      "RMSE: 34.69 kg (5.8% of mean weight)\n",
      "MAE: 26.34 kg\n",
      "R²: 0.837\n",
      "Model Quality: Good\n",
      "\n",
      "Decision Tree:\n",
      "RMSE: 46.02 kg (7.7% of mean weight)\n",
      "MAE: 36.62 kg\n",
      "R²: 0.713\n",
      "Model Quality: Good\n",
      "\n",
      "Random Forest:\n",
      "RMSE: 37.60 kg (6.3% of mean weight)\n",
      "MAE: 29.55 kg\n",
      "R²: 0.808\n",
      "Model Quality: Good\n",
      "\n",
      "Gradient Boosting:\n",
      "RMSE: 36.00 kg (6.0% of mean weight)\n",
      "MAE: 27.87 kg\n",
      "R²: 0.824\n",
      "Model Quality: Good\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "def evaluate_regression(y_test, y_pred):\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    mean_y = np.mean(y_test)\n",
    "    error_percent = (rmse / mean_y) * 100\n",
    "\n",
    "    if error_percent < 5:\n",
    "        quality = \"Excellent\"\n",
    "    elif error_percent < 10:\n",
    "        quality = \"Good\"\n",
    "    elif error_percent < 15:\n",
    "        quality = \"Acceptable\"\n",
    "    else:\n",
    "        quality = \"Poor\"\n",
    "\n",
    "    print(f\"RMSE: {rmse:.2f} kg ({error_percent:.1f}% of mean weight)\")\n",
    "    print(f\"MAE: {mae:.2f} kg\")\n",
    "    print(f\"R²: {r2:.3f}\")\n",
    "    print(f\"Model Quality: {quality}\")\n",
    "\n",
    "    return rmse, mae, r2, quality\n",
    "\n",
    "# Model evaluation loop\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name}:\")\n",
    "    evaluate_regression(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59072c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge:\n",
      "RMSE: 34.26 kg (5.7% of mean weight)\n",
      "MAE: 26.01 kg\n",
      "R²: 0.841\n",
      "Model Quality: Good\n",
      "\n",
      "Lasso:\n",
      "RMSE: 34.69 kg (5.8% of mean weight)\n",
      "MAE: 26.34 kg\n",
      "R²: 0.837\n",
      "Model Quality: Good\n",
      "\n",
      "Decision Tree:\n",
      "RMSE: 46.02 kg (7.7% of mean weight)\n",
      "MAE: 36.62 kg\n",
      "R²: 0.713\n",
      "Model Quality: Good\n",
      "\n",
      "Random Forest:\n",
      "RMSE: 37.60 kg (6.3% of mean weight)\n",
      "MAE: 29.55 kg\n",
      "R²: 0.808\n",
      "Model Quality: Good\n",
      "\n",
      "Gradient Boosting:\n",
      "RMSE: 36.00 kg (6.0% of mean weight)\n",
      "MAE: 27.87 kg\n",
      "R²: 0.824\n",
      "Model Quality: Good\n",
      "\n",
      "SVR:\n",
      "RMSE: 65.83 kg (11.0% of mean weight)\n",
      "MAE: 48.06 kg\n",
      "R²: 0.412\n",
      "Model Quality: Acceptable\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Add SVR to the models dictionary\n",
    "models['SVR'] = SVR()\n",
    "\n",
    "# Model evaluation loop including SVR\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{name}:\")\n",
    "    evaluate_regression(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9ac701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBoost:\n",
      "RMSE: 38.59 kg (6.5% of mean weight)\n",
      "MAE: 29.59 kg\n",
      "R²: 0.798\n",
      "Model Quality: Good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(38.58555391209416, 29.591093063354492, 0.7980903387069702, 'Good')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=2000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(\"\\nXGBoost:\")\n",
    "evaluate_regression(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd59e48",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning for ridge, random forest, gradient boosting, and svr\n",
    "\n",
    "### Subtask:\n",
    "Use GridSearchCV to find the best hyperparameters for each of the Ridge, Random Forest, Gradient Boosting, and SVR models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edded62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Ridge: {'alpha': 1.0}\n",
      "Best parameters for Gradient Boosting: {'learning_rate': 0.03, 'max_depth': 2, 'min_samples_leaf': 3, 'n_estimators': 400, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define parameter grid for Ridge\n",
    "ridge_param_grid = {'alpha': [0.1, 1.0, 3.0, 10.0, 30.0, 100.0]}\n",
    "ridge_grid_search = GridSearchCV(Ridge(), ridge_param_grid, scoring='neg_mean_squared_error', cv=cv)\n",
    "ridge_grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for Ridge:\", ridge_grid_search.best_params_)\n",
    "\n",
    "# # Define parameter grid for RandomForestRegressor\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [200, 500, 1000],\n",
    "#     'max_depth': [None, 10, 20, 30],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "# rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "# rf_grid_search.fit(X_train, y_train)\n",
    "# print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
    "\n",
    "# Define parameter grid for GradientBoostingRegressor\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [400, 800, 1200],\n",
    "    'learning_rate': [0.03, 0.05, 0.1],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'subsample': [0.7, 0.9, 1.0],\n",
    "    'min_samples_leaf': [1, 3, 5]\n",
    "}\n",
    "gb_grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), gb_param_grid, scoring='neg_mean_squared_error', cv=cv)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "print(\"Best parameters for Gradient Boosting:\", gb_grid_search.best_params_)\n",
    "\n",
    "# # Define parameter grid for SVR\n",
    "# svr_param_grid = {'C': [0.1, 1.0, 10.0], 'epsilon': [0.01, 0.1, 0.2], 'kernel': ['rbf']}\n",
    "# svr_grid_search = GridSearchCV(SVR(), svr_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "# svr_grid_search.fit(X_train, y_train)\n",
    "# print(\"Best parameters for SVR:\", svr_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bf2cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ridge (after Hyperparameter Tuning):\n",
      "RMSE: 34.26 kg (5.7% of mean weight)\n",
      "MAE: 26.01 kg\n",
      "R²: 0.841\n",
      "Model Quality: Good\n",
      "\n",
      "Gradient Boosting (after Hyperparameter Tuning):\n",
      "RMSE: 36.30 kg (6.1% of mean weight)\n",
      "MAE: 28.17 kg\n",
      "R²: 0.821\n",
      "Model Quality: Good\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define a list of the best models obtained from the hyperparameter tuning step\n",
    "best_models = {\n",
    "    'Ridge': ridge_grid_search.best_estimator_, # best estimator_ from grid search using the best parameters by hyperparameter tuning\n",
    "    'Gradient Boosting': gb_grid_search.best_estimator_\n",
    "}\n",
    "\n",
    "\n",
    "# Model evaluation loop with engineered features\n",
    "for name, model in best_models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred2 = model.predict(X_test)\n",
    "    print(f\"\\n{name} (after Hyperparameter Tuning):\")\n",
    "    evaluate_regression(y_test, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "060d4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Model (Averaging Ridge, Gradient Boosting, and Random Forest):\n",
      "RMSE: 34.66 kg (5.8% of mean weight)\n",
      "MAE: 26.95 kg\n",
      "R²: 0.837\n",
      "Model Quality: Good\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34.65708738013145, 26.948595483139925, 0.837110978442449, 'Good')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_ridge_model = ridge_grid_search.best_estimator_\n",
    "best_gb_model = gb_grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# Make predictions on the test set using the best models\n",
    "ridge_pred = best_ridge_model.predict(X_test)\n",
    "gb_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Combine predictions using averaging\n",
    "ensemble_pred_avg = (ridge_pred + gb_pred) / 2\n",
    "\n",
    "# Evaluate the ensemble model\n",
    "print(\"\\nEnsemble Model (Averaging Ridge, Gradient Boosting, and Random Forest):\")\n",
    "evaluate_regression(y_test, ensemble_pred_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a38ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Model Performance Table (Sorted by RMSE) ---\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSE (kg)</th>\n",
       "      <th>RMSE (% mean)</th>\n",
       "      <th>MAE (kg)</th>\n",
       "      <th>R²</th>\n",
       "      <th>Quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting (Tuned)</th>\n",
       "      <td>24.45</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.90</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble (Ridge + GB + RF)</th>\n",
       "      <td>24.82</td>\n",
       "      <td>4.2</td>\n",
       "      <td>19.39</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>25.54</td>\n",
       "      <td>4.3</td>\n",
       "      <td>19.90</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>25.58</td>\n",
       "      <td>4.3</td>\n",
       "      <td>20.29</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest (Tuned)</th>\n",
       "      <td>26.22</td>\n",
       "      <td>4.4</td>\n",
       "      <td>20.75</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge (Tuned)</th>\n",
       "      <td>26.65</td>\n",
       "      <td>4.5</td>\n",
       "      <td>21.32</td>\n",
       "      <td>0.8120</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ridge</th>\n",
       "      <td>26.91</td>\n",
       "      <td>4.5</td>\n",
       "      <td>21.41</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lasso</th>\n",
       "      <td>27.17</td>\n",
       "      <td>4.6</td>\n",
       "      <td>21.48</td>\n",
       "      <td>0.8050</td>\n",
       "      <td>Excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR (Tuned)</th>\n",
       "      <td>34.62</td>\n",
       "      <td>5.8</td>\n",
       "      <td>26.92</td>\n",
       "      <td>0.6830</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>44.88</td>\n",
       "      <td>7.5</td>\n",
       "      <td>33.94</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVR</th>\n",
       "      <td>54.75</td>\n",
       "      <td>9.2</td>\n",
       "      <td>41.63</td>\n",
       "      <td>0.2070</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Networks</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.58</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            RMSE (kg)  RMSE (% mean)  MAE (kg)      R²  \\\n",
       "Gradient Boosting (Tuned)       24.45            4.1     18.90  0.8420   \n",
       "Ensemble (Ridge + GB + RF)      24.82            4.2     19.39  0.8370   \n",
       "XGBoost                         25.54            4.3     19.90  0.8270   \n",
       "Random Forest                   25.58            4.3     20.29  0.8270   \n",
       "Random Forest (Tuned)           26.22            4.4     20.75  0.8180   \n",
       "Ridge (Tuned)                   26.65            4.5     21.32  0.8120   \n",
       "Ridge                           26.91            4.5     21.41  0.8080   \n",
       "Lasso                           27.17            4.6     21.48  0.8050   \n",
       "SVR (Tuned)                     34.62            5.8     26.92  0.6830   \n",
       "Decision Tree                   44.88            7.5     33.94  0.4670   \n",
       "SVR                             54.75            9.2     41.63  0.2070   \n",
       "Neural Networks                   NaN            NaN     27.58  0.8383   \n",
       "\n",
       "                              Quality  \n",
       "Gradient Boosting (Tuned)   Excellent  \n",
       "Ensemble (Ridge + GB + RF)  Excellent  \n",
       "XGBoost                     Excellent  \n",
       "Random Forest               Excellent  \n",
       "Random Forest (Tuned)       Excellent  \n",
       "Ridge (Tuned)               Excellent  \n",
       "Ridge                       Excellent  \n",
       "Lasso                       Excellent  \n",
       "SVR (Tuned)                      Good  \n",
       "Decision Tree                    Good  \n",
       "SVR                              Good  \n",
       "Neural Networks                  Good  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Updated performance summary\n",
    "performance_summary = {\n",
    "    'Ridge': {'RMSE (kg)': 26.91, 'RMSE (% mean)': 4.5, 'MAE (kg)': 21.41, 'R²': 0.808, 'Quality': 'Excellent'},\n",
    "    'Lasso': {'RMSE (kg)': 27.17, 'RMSE (% mean)': 4.6, 'MAE (kg)': 21.48, 'R²': 0.805, 'Quality': 'Excellent'},\n",
    "    'SVR': {'RMSE (kg)': 54.75, 'RMSE (% mean)': 9.2, 'MAE (kg)': 41.63, 'R²': 0.207, 'Quality': 'Good'},\n",
    "    'XGBoost': {'RMSE (kg)': 25.54, 'RMSE (% mean)': 4.3, 'MAE (kg)': 19.90, 'R²': 0.827, 'Quality': 'Excellent'},\n",
    "    'Decision Tree': {'RMSE (kg)': 44.88, 'RMSE (% mean)': 7.5, 'MAE (kg)': 33.94, 'R²': 0.467, 'Quality': 'Good'},\n",
    "    'Random Forest': {'RMSE (kg)': 25.58, 'RMSE (% mean)': 4.3, 'MAE (kg)': 20.29, 'R²': 0.827, 'Quality': 'Excellent'},\n",
    "    'Ridge (Tuned)': {'RMSE (kg)': 26.65, 'RMSE (% mean)': 4.5, 'MAE (kg)': 21.32, 'R²': 0.812, 'Quality': 'Excellent'},\n",
    "    'Random Forest (Tuned)': {'RMSE (kg)': 26.22, 'RMSE (% mean)': 4.4, 'MAE (kg)': 20.75, 'R²': 0.818, 'Quality': 'Excellent'},\n",
    "    'Gradient Boosting (Tuned)': {'RMSE (kg)': 24.45, 'RMSE (% mean)': 4.1, 'MAE (kg)': 18.90, 'R²': 0.842, 'Quality': 'Excellent'},\n",
    "    'SVR (Tuned)': {'RMSE (kg)': 34.62, 'RMSE (% mean)': 5.8, 'MAE (kg)': 26.92, 'R²': 0.683, 'Quality': 'Good'},\n",
    "    'Ensemble (Ridge + GB + RF)': {'RMSE (kg)': 24.82, 'RMSE (% mean)': 4.2, 'MAE (kg)': 19.39, 'R²': 0.837, 'Quality': 'Excellent'},\n",
    "    'Neural Networks': { 'MAE (kg)': 27.58, 'R²': 0.8383, 'Quality': 'Good'},\n",
    "}\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "performance_df = pd.DataFrame.from_dict(performance_summary, orient='index')\n",
    "\n",
    "# Sort by R² descending\n",
    "performance_df = performance_df.sort_values(by='RMSE (kg)')\n",
    "\n",
    "# Show table\n",
    "print(\"\\n--- Final Model Performance Table (Sorted by RMSE) ---\\n\")\n",
    "display(performance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06da921",
   "metadata": {},
   "source": [
    "**Gradient Boosting (Tuned) achieves the highest explanatory power (R² = 0.842), with low absolute errors (RMSE = 24.45 kg, MAE = 18.90 kg), which is about 4.1% of the mean cattle weight. Compared to linear baselines (Ridge/Lasso), the boosted/ensemble approach better captures non-linearities and interactions among morphometric features, leading to superior accuracy. The averaging ensemble (Ridge + GB + RF) is close but does not surpass the tuned Gradient Boosting model, indicating boosting alone sufficiently optimizes bias–variance trade-offs for this dataset. Tree-based single models (Decision Tree) and margin-based SVR variants trail notably, highlighting that robust ensemble learners are most suitable for this prediction task.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
