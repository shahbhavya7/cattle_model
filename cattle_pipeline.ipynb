{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJpWYAeYyFc0NYZL+1L243",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shahbhavya7/cattle_model/blob/main/cattle_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "acMDpNdJMnWa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats.mstats import winsorize"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds=pd.read_excel('cattle_analysis.xlsx')"
      ],
      "metadata": {
        "id": "YhSbgUlMM7NC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.info()"
      ],
      "metadata": {
        "id": "o8QoOsMRNFjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_matrix=ds.corr()\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0f4_MGJsrEAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.columns"
      ],
      "metadata": {
        "id": "EDe2YOeOx43E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.isnull().sum()"
      ],
      "metadata": {
        "id": "XAVuIEEHNLRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds.duplicated().sum()"
      ],
      "metadata": {
        "id": "55uBIcBwNxfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds=ds.drop(columns=['AnimalNo'])"
      ],
      "metadata": {
        "id": "XWWcvZKAZZ8L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=ds.iloc[:,:-1]\n",
        "y=ds.iloc[:,-1]"
      ],
      "metadata": {
        "id": "ccNcGhKYN20G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "n8_1Rgx17Ms6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in X_train.columns:\n",
        "  sns.boxplot(data=X_train,x=col)\n",
        "  plt.show()\n",
        "  print('\\n')\n"
      ],
      "metadata": {
        "id": "kCZiDBc7ZtYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_limits(X,lower=0.02,upper=0.98):\n",
        "  limits={col:(np.quantile(X[col],lower),(np.quantile(X[col],upper))) for col in X.columns}\n",
        "  return limits"
      ],
      "metadata": {
        "id": "r7XTeBcs8qZA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_limits(X,limits):\n",
        "  X_win=X.copy()\n",
        "  for col in X.columns:\n",
        "    lower,upper=limits[col]\n",
        "    X_win[col]=np.clip(X[col],lower,upper)\n",
        "  return X_win"
      ],
      "metadata": {
        "id": "hSxrelqN--Qd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_manual_cap_limits(df, column):\n",
        "    Q1 = df[column].quantile(0.25)\n",
        "    Q3 = df[column].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_limit = Q1 - 1.5 * IQR\n",
        "    upper_limit = Q3 + 1.5 * IQR\n",
        "    return lower_limit, upper_limit"
      ],
      "metadata": {
        "id": "PlhDYEl4cw2k"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class Winsorizer(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,lower=0.02,upper=0.98):\n",
        "    self.lower_quantile=lower\n",
        "    self.upper_quantile=upper\n",
        "    self.limits={}\n",
        "\n",
        "  def fit(self,X,y=None):\n",
        "    self.limits=get_limits(X,self.lower_quantile,self.upper_quantile)\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "    return apply_limits(X,self.limits)"
      ],
      "metadata": {
        "id": "W_ZrNSoU_svi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Manual_capper(BaseEstimator,TransformerMixin):\n",
        "  def __init__(self,column):\n",
        "    self.column=column\n",
        "    self.limits=(None,None)\n",
        "\n",
        "  def fit(self,X,y=None):\n",
        "    self.limits=get_manual_cap_limits(X,self.column)\n",
        "    return self\n",
        "\n",
        "  def transform(self,X):\n",
        "    X_new=X.copy()\n",
        "    lower,upper=self.limits\n",
        "    X_new[self.column]=np.clip(X_new[self.column],lower,upper)\n",
        "    return X_new"
      ],
      "metadata": {
        "id": "gcLrCZTOBPto"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_new = X.copy()\n",
        "        X_new['Rump_Wither_Ratio'] = X_new['Rumpheight'] / X_new['WHHeightAtWither']\n",
        "        X_new['Length_Wither_Ratio'] = X_new['BLBodylengthcm'] / X_new['WHHeightAtWither']\n",
        "        X_new = X_new.drop(columns=['Rumpheight','WHHeightAtWither','BLBodylengthcm'])\n",
        "        return X_new"
      ],
      "metadata": {
        "id": "Ca53Pf7qDCQp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_regression(y_test, y_pred):\n",
        "    # Calculate errors\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    mean_y = np.mean(y_test)\n",
        "\n",
        "    # Percentages\n",
        "    rmse_percent = (rmse / mean_y) * 100\n",
        "    mae_percent = (mae / mean_y) * 100\n",
        "\n",
        "    # Quality assessment (combined RMSE% and R²)\n",
        "    if rmse_percent < 5 and r2 > 0.85:\n",
        "        quality = \"Excellent\"\n",
        "    elif rmse_percent < 10 and r2 > 0.75:\n",
        "        quality = \"Good\"\n",
        "    elif rmse_percent < 15 and r2 > 0.6:\n",
        "        quality = \"Acceptable\"\n",
        "    else:\n",
        "        quality = \"Poor\"\n",
        "\n",
        "    # Print results\n",
        "    print(f\"RMSE: {rmse:.2f} kg ({rmse_percent:.1f}% of mean weight)\")\n",
        "    print(f\"MAE: {mae:.2f} kg ({mae_percent:.1f}% of mean weight)\")\n",
        "    print(f\"R²: {r2:.3f}\")\n",
        "    print(f\"Model Quality: {quality}\")\n",
        "\n",
        "    return rmse, mae, r2, quality\n"
      ],
      "metadata": {
        "id": "2ZJIpMtF9JFb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge,Lasso ,LinearRegression\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('features',FeatureEngineer()),\n",
        "    ('winsor', Winsorizer()),\n",
        "    ('capper', Manual_capper('CannonBoneDiameter')),\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor())\n",
        "])\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "id": "W3RUUWYOBCNu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_regression(y_test, y_pred)"
      ],
      "metadata": {
        "id": "8qlFV1ek-JmW",
        "outputId": "091dabdc-4764-4000-d6d5-a436c55d41f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 34.74 kg (5.8% of mean weight)\n",
            "MAE: 26.80 kg (4.5% of mean weight)\n",
            "R²: 0.836\n",
            "Model Quality: Good\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(np.float64(34.73980699981818), 26.801153846153852, 0.8363324826736054, 'Good')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for col in X_train_win.columns:\n",
        "#   sns.boxplot(data=X_train_win,x=col)\n",
        "#   plt.show()\n",
        "#   print('\\n')"
      ],
      "metadata": {
        "id": "V2zJyIkwcKCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew_result = X_win.skew(numeric_only=True).to_dict()\n",
        "# print(skew_result)"
      ],
      "metadata": {
        "id": "d9Vc004VdPgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# skew_result = y_win.skew(numeric_only=True)\n",
        "# print(skew_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1q6j9Dv_dnXR",
        "outputId": "aa63fdc8-e7b4-499b-9045-e7b5acb8a660"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.12408513676691647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# Ridge\n",
        "ridge_param_grid = {'alpha': [0.1, 1.0, 10.0]}\n",
        "ridge_grid_search = GridSearchCV(Ridge(), ridge_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "ridge_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for Ridge:\", ridge_grid_search.best_params_)\n",
        "\n",
        "# Lasso\n",
        "lasso_param_grid = {'alpha': [0.001, 0.01, 0.1, 1.0, 10.0]}\n",
        "lasso_grid_search = GridSearchCV(Lasso(max_iter=5000), lasso_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for Lasso:\", lasso_grid_search.best_params_)\n",
        "\n",
        "# Linear Regression (no hyperparameters to tune, but still use CV for consistency)\n",
        "linreg_param_grid = {}\n",
        "linreg_grid_search = GridSearchCV(LinearRegression(), linreg_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "linreg_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for Linear Regression (no tuning):\", linreg_grid_search.best_params_)\n",
        "\n",
        "# Random Forest\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5]\n",
        "}\n",
        "rf_grid_search = GridSearchCV(RandomForestRegressor(random_state=42), rf_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "rf_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for Random Forest:\", rf_grid_search.best_params_)\n",
        "\n",
        "# XGBoost\n",
        "xgb_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "xgb_grid_search = GridSearchCV(\n",
        "    XGBRegressor(random_state=42, n_jobs=-1, verbosity=0),\n",
        "    xgb_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5\n",
        ")\n",
        "xgb_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for XGBoost:\", xgb_grid_search.best_params_)\n",
        "\n",
        "# LightGBM\n",
        "lgbm_param_grid = {\n",
        "    'n_estimators': [100, 200],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': [-1, 5, 10]\n",
        "}\n",
        "lgbm_grid_search = GridSearchCV(\n",
        "    LGBMRegressor(random_state=42),\n",
        "    lgbm_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5\n",
        ")\n",
        "lgbm_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for LightGBM:\", lgbm_grid_search.best_params_)\n",
        "\n",
        "# CatBoost\n",
        "cat_param_grid = {\n",
        "    'iterations': [200, 500],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'depth': [4, 6, 8]\n",
        "}\n",
        "cat_grid_search = GridSearchCV(\n",
        "    CatBoostRegressor(random_state=42, verbose=0),\n",
        "    cat_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5\n",
        ")\n",
        "cat_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for CatBoost:\", cat_grid_search.best_params_)\n",
        "\n",
        "# SVR\n",
        "svr_param_grid = {\n",
        "    'C': [0.1, 1.0, 10.0],\n",
        "    'epsilon': [0.01, 0.1, 0.2],\n",
        "    'kernel': ['rbf']\n",
        "}\n",
        "svr_grid_search = GridSearchCV(SVR(), svr_param_grid, scoring='neg_mean_squared_error', cv=5)\n",
        "svr_grid_search.fit(X_train, y_train)\n",
        "print(\"Best parameters for SVR:\", svr_grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "_vBQaDHBsrrZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models = {\n",
        "    'Ridge': ridge_grid_search.best_estimator_,\n",
        "    'Lasso':lasso_grid_search.best_estimator_,\n",
        "    'LinearRegression':linreg_grid_search.best_estimator_,\n",
        "    'Random Forest': rf_grid_search.best_estimator_,\n",
        "    'XGboost': xgb_grid_search.best_estimator_,\n",
        "    'Lightboost':lgbm_grid_search.best_estimator_,\n",
        "    'Catboost': cat_grid_search.best_estimator_,\n",
        "    'SVR': svr_grid_search.best_estimator_\n",
        "}\n",
        "for name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    print(f\"\\n{name}:\")\n",
        "    evaluate_regression(y_test, y_pred)"
      ],
      "metadata": {
        "id": "tedujKmmu_Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RMSE: 30.04 kg (5.0% of mean weight)\n",
        "MAE: 22.97 kg (3.8% of mean weight)\n",
        "R²: 0.866\n",
        "Model Quality: Good\n",
        "(np.float64(30.039672370500533), 22.9675643106626, 0.866380202946881, 'Good')"
      ],
      "metadata": {
        "id": "Mzrqg-N5NYmR"
      }
    }
  ]
}